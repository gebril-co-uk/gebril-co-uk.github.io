
<head>
    <meta charset="UTF-8">
    <title>Boosting algorithms for predicting end-point temperature in BOF steelmaking using big industrial datasets</title>
    <meta name="description" content="This study applies machine learning to predict end-point temperature in basic oxygen furnace steelmaking, using over 20,000 heats to evaluate boosting and ensemble algorithms. CatBoost outperforms others, highlighting the value of large datasets and advanced models in industrial process optimisation." />
    <meta name="robots" content="index, follow">
    <link rel="icon" type="image/png" href="https://gebril.co.uk/files/Favicon.png"/>
    <link rel="stylesheet" href="styles/shared.css">
    <link rel="stylesheet" href="styles/research.css">
    <link rel="stylesheet" href="styles/navbar.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400;500;600;700&display=swap">
    <link rel="stylesheet" href="styles/photographs.css"> <!-- Link to the new CSS file -->

<style>
.abstract-box {
        max-height: 850px; /* Adjust as needed */
        overflow: hidden;
        text-align: justify;
        gap: 5px; /* Adjust as needed */ /* or use  line-height: 1.5; */
        flex: 1; /* Added to make it take the remaining space */
        font-size: 18px;
        font-weight: 40;
        font-family: 'Arial', sans-serif;
        color: #111111;
        /*  color:#4A9DFF;   */
        /*margin: 10px;  */
    
     }

     .links {
    margin-top: 60px;
        }



    .links ul li a:link, 
.links ul li a:active {
    color: blue;
    text-decoration: none;
}
.links ul li a:hover {
    text-decoration: underline;
}
.links ul li a:visited, 
.links ul li a:active {
    color: darkred;
}
.links ul li a:hover {
    text-decoration: underline;
}
.links ul li a:visited {
    color: darkred !important;
}
</style>

</head>
<body>
    <div class="nav" id="navbar">
        <div class="innernav">
            <div class="navtext">
                <div class="logo">
                    <li style="float: left;"><a href="index">Alloy Design & Phase Transformations Research Group</a></li>
                </div>
                <div class="navlinks">
                    <li style="float: right;"><a href="photographs">Photographs</a></li>
                    <li style="float: right;"><a href="equipment">Equipment</a></li>
                    <li style="float: right;"><a href="teaching">Teaching</a></li>
                    <li style="float: right;"><a href="research">Research</a></li>
                    <li style="float: right;"><a href="group">Group</a></li>
                    <li style="float: right;"><a href="index">About</a></li>
                </div>
            </div>
        </div>
    </div>



    <div class="page">
         <h1 style="color: darkred; text-align: center; font-size: 24px;">Boosting algorithms for predicting end-point temperature in BOF steelmaking using big industrial datasets</h1>

        <h1 style="color: black; text-align: center;font-size: 20px;">Jian-bo Zhang, Maryam Khaksar Ghalati, Jun Fu, Xiao-an Yang, G. M. A. M. El-Fallah and Hongbiao Dongh</h1>

        <h3 style="text-align: center; margin-bottom: 5px;">Abstract</h3>

        

            <!-- <div class="grid-container"> -->
                <div class="abstract-box">
                        The application of machine learning was investigated for predicting end-point temperature in the basic oxygen furnace steelmaking process, addressing gaps in the field, particularly large-scale dataset sizes and the underutilization of boosting algorithms. Utilizing a substantial dataset containing over 20,000 heats, significantly bigger than those in previous studies, a comprehensive evaluation of five advanced machine learning models was conducted. These include four ensemble learning algorithms: XGBoost, LightGBM, CatBoost (three boosting algorithms), along with random forest (a bagging algorithm), as well as a neural network model, namely the multilayer perceptron. Our comparative analysis reveals that Bayesian-optimized boosting models demonstrate exceptional robustness and accuracy, achieving the highest R-squared values, the lowest root mean square error, and lowest mean absolute error, along with the best hit ratio. CatBoost exhibited superior performance, with its test R-squared improving by 4.2% compared to that of the random forest and by 0.8% compared to that of the multilayer perceptron. This highlights the efficacy of boosting algorithms in refining complex industrial processes. Additionally, our investigation into the impact of varying dataset sizes, ranging from 500 to 20,000 heats, on model accuracy underscores the importance of leveraging larger-scale datasets to improve the accuracy and stability of predictive models.
                </div>

        <div class="links">
            <ul>
                <li><a href="papers/Boosting_algorithms.pdf" target="_blank">Download paper</a></li>
                <li><a href="https://link.springer.com/article/10.1007/s42243-025-01454-z?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=oa_20250407&utm_content=10.1007/s42243-025-01454-z">Access paper from journal</a></li>
            </ul>
        </div>
    </div>
</body>
</html>

        

